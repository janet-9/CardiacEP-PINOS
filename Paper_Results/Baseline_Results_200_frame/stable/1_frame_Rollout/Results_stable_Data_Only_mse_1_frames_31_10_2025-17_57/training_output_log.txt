
### --------- ###

Loading datasets from /storage/ceph/usr/k23086865/Projects/PINNS/2D_AP_PINO/datasets/openCARP_Data/stable/0.8_trn-tst_200_frames_1_inputsteps_1_outputsteps_SEQ
datasets/openCARP_Data/stable/0.8_trn-tst_200_frames_1_inputsteps_1_outputsteps_SEQ/dataset_info_101_1.0.txt
dx: 0.09900990099009901
dy: 0.09900990099009901
delta_t: 5 ms
V_rest = 0.0, V_amp = 0.99
Time boundary: 1 frames
n_train: 159
training_resolution: 101

### --------- ###


### --------- ###

 Number of testing samples: [39]
 Testing resolutions: [101]
 Testing Conductivities: [1.0]
 Testing batch sizes: [5]

### --------- ###

Loading Training Dataset for resolution 101 with 159 samples with 1.0 conductivity multiplier
Loading Testing Dataset for resolution 101 with 39 samples with 1.0 conductivity multiplier
Input Tensor: torch.Size([39, 2, 1, 101, 101])
Output Tensor: torch.Size([39, 2, 1, 101, 101])

### --------- ###

Mesh size: 10 cm x 10 cm
Sample Time Boundary: 1 frames with spacing 5 ms =  0.0 ms 
Embedding Grid Boundaries = [[0, 0.0], [0, 10], [0, 10]]
Sample Data shape: torch.Size([2, 1, 101, 101]): channels=2, time=1, H=101, W=101


### --------- ###


Model has 9450530 parameters.
Calculating Residual Loss via Finite Difference

### INITIAL TRAINING ROUND ###


### MODEL ###
 FNO(
  (positional_embedding): GridEmbeddingND()
  (fno_blocks): FNOBlocks(
    (convs): ModuleList(
      (0-3): 4 x SpectralConv(
        (weight): DenseTensor(shape=torch.Size([32, 32, 8, 16, 9]), rank=None)
      )
    )
    (fno_skips): ModuleList(
      (0-3): 4 x Flattened1dConv(
        (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)
      )
    )
    (channel_mlp): ModuleList(
      (0-3): 4 x ChannelMLP(
        (fcs): ModuleList(
          (0): Conv1d(32, 16, kernel_size=(1,), stride=(1,))
          (1): Conv1d(16, 32, kernel_size=(1,), stride=(1,))
        )
      )
    )
    (channel_mlp_skips): ModuleList(
      (0-3): 4 x SoftGating()
    )
  )
  (lifting): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(5, 64, kernel_size=(1,), stride=(1,))
      (1): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
    )
  )
  (projection): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
      (1): Conv1d(64, 2, kernel_size=(1,), stride=(1,))
    )
  )
)

### OPTIMIZER ###
 AdamW (
Parameter Group 0
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-06
    initial_lr: 0.0005
    lr: 0.0005
    weight_decay: 1e-05
)

### SCHEDULER ###
 <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f87f9c4eca0>

### LOSSES ###

 * Train: <AP_neuralop_utils.losses.data_losses.LpLoss object at 0x7f87f9c4edf0>

 * Test: {'l2': <AP_neuralop_utils.losses.data_losses.LpLoss object at 0x7f87f9c4edf0>, 'mse': <neuralop.losses.data_losses.MSELoss object at 0x7f87f9c4ed60>, 'rmse': <AP_neuralop_utils.losses.data_losses.RMSELoss object at 0x7f87f81c6160>, 'ap_phys': <AP_neuralop_utils.losses.equation_losses.APLoss object at 0x7f86b4064cd0>, 'boundary': <AP_neuralop_utils.losses.data_losses.BoundaryLoss object at 0x7f87f81c60d0>, 'ic': <AP_neuralop_utils.losses.data_losses.ICLoss object at 0x7f86b4064a30>, 'bcn': <AP_neuralop_utils.losses.data_losses.BCNeumann object at 0x7f86b4064970>}

 * Initial Training Round for 100 epochs
Saving best model according to (101, 1.0)_mse
Training on 159 samples
Testing on [39] samples         on resolutions [(101, 1.0)].
Raw outputs of shape torch.Size([15, 2, 1, 101, 101])
[0] time=5.86, avg_loss=1.7337, train_err=25.0605
Eval: (101, 1.0)_l2=1.5555, (101, 1.0)_mse=0.2561, (101, 1.0)_rmse=0.1038, (101, 1.0)_ap_phys=0.1519, (101, 1.0)_boundary=0.0626, (101, 1.0)_ic=0.0379, (101, 1.0)_bcn=0.0001
[Rank 0]: saved training state to Results_stable_Data_Only_mse_1_frames_31_10_2025-17_57
[10] time=3.85, avg_loss=0.7771, train_err=11.2323
Eval: (101, 1.0)_l2=0.7231, (101, 1.0)_mse=0.0527, (101, 1.0)_rmse=0.0468, (101, 1.0)_ap_phys=1.7152, (101, 1.0)_boundary=0.0277, (101, 1.0)_ic=0.0184, (101, 1.0)_bcn=0.0144
[Rank 0]: saved training state to Results_stable_Data_Only_mse_1_frames_31_10_2025-17_57
[20] time=3.77, avg_loss=0.2187, train_err=3.1614
Eval: (101, 1.0)_l2=0.2505, (101, 1.0)_mse=0.0061, (101, 1.0)_rmse=0.0159, (101, 1.0)_ap_phys=3.2728, (101, 1.0)_boundary=0.0055, (101, 1.0)_ic=0.0016, (101, 1.0)_bcn=0.0177
[Rank 0]: saved training state to Results_stable_Data_Only_mse_1_frames_31_10_2025-17_57
[30] time=3.65, avg_loss=0.1670, train_err=2.4146
Eval: (101, 1.0)_l2=0.1772, (101, 1.0)_mse=0.0031, (101, 1.0)_rmse=0.0114, (101, 1.0)_ap_phys=4.2192, (101, 1.0)_boundary=0.0030, (101, 1.0)_ic=0.0007, (101, 1.0)_bcn=0.0164
[Rank 0]: saved training state to Results_stable_Data_Only_mse_1_frames_31_10_2025-17_57
[40] time=3.79, avg_loss=0.1321, train_err=1.9091
Eval: (101, 1.0)_l2=0.1464, (101, 1.0)_mse=0.0021, (101, 1.0)_rmse=0.0094, (101, 1.0)_ap_phys=4.2025, (101, 1.0)_boundary=0.0025, (101, 1.0)_ic=0.0007, (101, 1.0)_bcn=0.0144
[Rank 0]: saved training state to Results_stable_Data_Only_mse_1_frames_31_10_2025-17_57
[50] time=3.69, avg_loss=0.1362, train_err=1.9681
Eval: (101, 1.0)_l2=0.1281, (101, 1.0)_mse=0.0016, (101, 1.0)_rmse=0.0083, (101, 1.0)_ap_phys=4.6567, (101, 1.0)_boundary=0.0019, (101, 1.0)_ic=0.0003, (101, 1.0)_bcn=0.0138
[Rank 0]: saved training state to Results_stable_Data_Only_mse_1_frames_31_10_2025-17_57
[60] time=3.86, avg_loss=0.1199, train_err=1.7334
Eval: (101, 1.0)_l2=0.1049, (101, 1.0)_mse=0.0011, (101, 1.0)_rmse=0.0066, (101, 1.0)_ap_phys=4.9296, (101, 1.0)_boundary=0.0015, (101, 1.0)_ic=0.0003, (101, 1.0)_bcn=0.0130
[Rank 0]: saved training state to Results_stable_Data_Only_mse_1_frames_31_10_2025-17_57
[70] time=3.71, avg_loss=0.1295, train_err=1.8713
Eval: (101, 1.0)_l2=0.1359, (101, 1.0)_mse=0.0020, (101, 1.0)_rmse=0.0091, (101, 1.0)_ap_phys=5.1945, (101, 1.0)_boundary=0.0016, (101, 1.0)_ic=0.0003, (101, 1.0)_bcn=0.0120
[80] time=3.60, avg_loss=0.0956, train_err=1.3814
Eval: (101, 1.0)_l2=0.1002, (101, 1.0)_mse=0.0010, (101, 1.0)_rmse=0.0064, (101, 1.0)_ap_phys=5.0574, (101, 1.0)_boundary=0.0013, (101, 1.0)_ic=0.0003, (101, 1.0)_bcn=0.0112
[Rank 0]: saved training state to Results_stable_Data_Only_mse_1_frames_31_10_2025-17_57
[90] time=3.78, avg_loss=0.0950, train_err=1.3732
Eval: (101, 1.0)_l2=0.0915, (101, 1.0)_mse=0.0008, (101, 1.0)_rmse=0.0058, (101, 1.0)_ap_phys=5.2803, (101, 1.0)_boundary=0.0011, (101, 1.0)_ic=0.0002, (101, 1.0)_bcn=0.0109
[Rank 0]: saved training state to Results_stable_Data_Only_mse_1_frames_31_10_2025-17_57
