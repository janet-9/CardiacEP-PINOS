
### --------- ###

Loading datasets from /storage/ceph/usr/k23086865/Projects/PINNS/2D_AP_PINO/datasets/openCARP_Data/chaotic/0.8_trn-tst_200_frames_5_inputsteps_5_outputsteps_SEQ
datasets/openCARP_Data/chaotic/0.8_trn-tst_200_frames_5_inputsteps_5_outputsteps_SEQ/dataset_info_101_1.0.txt
dx: 0.09900990099009901
dy: 0.09900990099009901
delta_t: 5 ms
V_rest = 0.0, V_amp = 0.98
Time boundary: 5 frames
n_train: 152
training_resolution: 101

### --------- ###


### --------- ###

 Number of testing samples: [30]
 Testing resolutions: [101]
 Testing Conductivities: [1.0]
 Testing batch sizes: [5]

### --------- ###

Loading Training Dataset for resolution 101 with 152 samples with 1.0 conductivity multiplier
Loading Testing Dataset for resolution 101 with 30 samples with 1.0 conductivity multiplier
Input Tensor: torch.Size([30, 2, 5, 101, 101])
Output Tensor: torch.Size([30, 2, 5, 101, 101])

### --------- ###

Mesh size: 10 cm x 10 cm
Sample Time Boundary: 5 frames with spacing 5 ms =  20.0 ms 
Embedding Grid Boundaries = [[0, 20.0], [0, 10], [0, 10]]
Sample Data shape: torch.Size([2, 5, 101, 101]): channels=2, time=5, H=101, W=101


### --------- ###


Model has 9450530 parameters.
Calculating Residual Loss via Finite Difference

### INITIAL TRAINING ROUND ###


### MODEL ###
 FNO(
  (positional_embedding): GridEmbeddingND()
  (fno_blocks): FNOBlocks(
    (convs): ModuleList(
      (0-3): 4 x SpectralConv(
        (weight): DenseTensor(shape=torch.Size([32, 32, 8, 16, 9]), rank=None)
      )
    )
    (fno_skips): ModuleList(
      (0-3): 4 x Flattened1dConv(
        (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)
      )
    )
    (channel_mlp): ModuleList(
      (0-3): 4 x ChannelMLP(
        (fcs): ModuleList(
          (0): Conv1d(32, 16, kernel_size=(1,), stride=(1,))
          (1): Conv1d(16, 32, kernel_size=(1,), stride=(1,))
        )
      )
    )
    (channel_mlp_skips): ModuleList(
      (0-3): 4 x SoftGating()
    )
  )
  (lifting): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(5, 64, kernel_size=(1,), stride=(1,))
      (1): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
    )
  )
  (projection): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
      (1): Conv1d(64, 2, kernel_size=(1,), stride=(1,))
    )
  )
)

### OPTIMIZER ###
 AdamW (
Parameter Group 0
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-06
    initial_lr: 0.0005
    lr: 0.0005
    weight_decay: 1e-05
)

### SCHEDULER ###
 <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f3fcae84490>

### LOSSES ###

 * Train: <AP_neuralop_utils.losses.data_losses.LpLoss object at 0x7f3fcae84520>

 * Test: {'l2': <AP_neuralop_utils.losses.data_losses.LpLoss object at 0x7f3fcae84520>, 'mse': <neuralop.losses.data_losses.MSELoss object at 0x7f3fcae84550>, 'rmse': <AP_neuralop_utils.losses.data_losses.RMSELoss object at 0x7f3fcae844f0>, 'ap_phys': <AP_neuralop_utils.losses.equation_losses.APLoss object at 0x7f3eb8e01fa0>, 'boundary': <AP_neuralop_utils.losses.data_losses.BoundaryLoss object at 0x7f3fcae848e0>, 'ic': <AP_neuralop_utils.losses.data_losses.ICLoss object at 0x7f3fcae84880>, 'bcn': <AP_neuralop_utils.losses.data_losses.BCNeumann object at 0x7f3eb9037a60>, 'phys_loss': <AP_neuralop_utils.losses.meta_losses.WeightedSumLoss object at 0x7f3eb8e01dc0>}

 * Initial Training Round for 100 epochs
Training on 152 samples
Testing on [30] samples         on resolutions [(101, 1.0)].
Raw outputs of shape torch.Size([15, 2, 5, 101, 101])
[0] time=18.39, avg_loss=6.9435, train_err=95.9469
Eval: (101, 1.0)_l2=8.6640, (101, 1.0)_mse=0.2879, (101, 1.0)_rmse=0.1073, (101, 1.0)_ap_phys=1.1139, (101, 1.0)_boundary=0.1217, (101, 1.0)_ic=0.0396, (101, 1.0)_bcn=0.0003, (101, 1.0)_phys_loss=0.0151
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[10] time=15.58, avg_loss=4.2906, train_err=59.2890
Eval: (101, 1.0)_l2=6.0916, (101, 1.0)_mse=0.1367, (101, 1.0)_rmse=0.0739, (101, 1.0)_ap_phys=3.2128, (101, 1.0)_boundary=0.0564, (101, 1.0)_ic=0.0258, (101, 1.0)_bcn=0.0059, (101, 1.0)_phys_loss=0.0353
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[20] time=14.01, avg_loss=2.0549, train_err=28.3951
Eval: (101, 1.0)_l2=3.8817, (101, 1.0)_mse=0.0554, (101, 1.0)_rmse=0.0469, (101, 1.0)_ap_phys=4.9538, (101, 1.0)_boundary=0.0250, (101, 1.0)_ic=0.0104, (101, 1.0)_bcn=0.0216, (101, 1.0)_phys_loss=0.0527
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[30] time=17.28, avg_loss=1.4804, train_err=20.4560
Eval: (101, 1.0)_l2=3.3887, (101, 1.0)_mse=0.0414, (101, 1.0)_rmse=0.0405, (101, 1.0)_ap_phys=4.7929, (101, 1.0)_boundary=0.0193, (101, 1.0)_ic=0.0085, (101, 1.0)_bcn=0.0207, (101, 1.0)_phys_loss=0.0509
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[40] time=16.29, avg_loss=1.2948, train_err=17.8918
Eval: (101, 1.0)_l2=3.2817, (101, 1.0)_mse=0.0391, (101, 1.0)_rmse=0.0393, (101, 1.0)_ap_phys=4.5081, (101, 1.0)_boundary=0.0166, (101, 1.0)_ic=0.0075, (101, 1.0)_bcn=0.0232, (101, 1.0)_phys_loss=0.0481
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[50] time=14.60, avg_loss=1.3494, train_err=18.6461
Eval: (101, 1.0)_l2=4.1087, (101, 1.0)_mse=0.0615, (101, 1.0)_rmse=0.0495, (101, 1.0)_ap_phys=3.7003, (101, 1.0)_boundary=0.0291, (101, 1.0)_ic=0.0102, (101, 1.0)_bcn=0.0214, (101, 1.0)_phys_loss=0.0402
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[60] time=16.64, avg_loss=0.9384, train_err=12.9672
Eval: (101, 1.0)_l2=3.7192, (101, 1.0)_mse=0.0514, (101, 1.0)_rmse=0.0451, (101, 1.0)_ap_phys=3.5325, (101, 1.0)_boundary=0.0228, (101, 1.0)_ic=0.0084, (101, 1.0)_bcn=0.0252, (101, 1.0)_phys_loss=0.0387
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[70] time=13.58, avg_loss=0.9544, train_err=13.1880
Eval: (101, 1.0)_l2=3.5624, (101, 1.0)_mse=0.0449, (101, 1.0)_rmse=0.0423, (101, 1.0)_ap_phys=3.8801, (101, 1.0)_boundary=0.0237, (101, 1.0)_ic=0.0102, (101, 1.0)_bcn=0.0271, (101, 1.0)_phys_loss=0.0425
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[80] time=16.96, avg_loss=0.8367, train_err=11.5613
Eval: (101, 1.0)_l2=3.1641, (101, 1.0)_mse=0.0367, (101, 1.0)_rmse=0.0380, (101, 1.0)_ap_phys=3.6904, (101, 1.0)_boundary=0.0165, (101, 1.0)_ic=0.0066, (101, 1.0)_bcn=0.0295, (101, 1.0)_phys_loss=0.0405
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[90] time=14.15, avg_loss=0.9200, train_err=12.7129
Eval: (101, 1.0)_l2=3.4396, (101, 1.0)_mse=0.0440, (101, 1.0)_rmse=0.0417, (101, 1.0)_ap_phys=3.1566, (101, 1.0)_boundary=0.0186, (101, 1.0)_ic=0.0075, (101, 1.0)_bcn=0.0276, (101, 1.0)_phys_loss=0.0351
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55

### MAIN TRAINING ROUND ###


### MODEL ###
 FNO(
  (positional_embedding): GridEmbeddingND()
  (fno_blocks): FNOBlocks(
    (convs): ModuleList(
      (0-3): 4 x SpectralConv(
        (weight): DenseTensor(shape=torch.Size([32, 32, 8, 16, 9]), rank=None)
      )
    )
    (fno_skips): ModuleList(
      (0-3): 4 x Flattened1dConv(
        (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)
      )
    )
    (channel_mlp): ModuleList(
      (0-3): 4 x ChannelMLP(
        (fcs): ModuleList(
          (0): Conv1d(32, 16, kernel_size=(1,), stride=(1,))
          (1): Conv1d(16, 32, kernel_size=(1,), stride=(1,))
        )
      )
    )
    (channel_mlp_skips): ModuleList(
      (0-3): 4 x SoftGating()
    )
  )
  (lifting): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(5, 64, kernel_size=(1,), stride=(1,))
      (1): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
    )
  )
  (projection): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
      (1): Conv1d(64, 2, kernel_size=(1,), stride=(1,))
    )
  )
)

### OPTIMIZER ###
 AdamW (
Parameter Group 0
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-06
    initial_lr: 0.0005
    lr: 0.0004877641290737878
    weight_decay: 1e-05
)

### SCHEDULER ###
 <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f3fcae84490>

### AGGREGATOR ###
None (not used for this configuration)

### LOSSES ###

 * Train: 1.0*<AP_neuralop_utils.losses.data_losses.LpLoss object at 0x7f3fcae84520> + 0.01*<AP_neuralop_utils.losses.equation_losses.APLoss object at 0x7f3eb8e01fa0> + 0.1*<AP_neuralop_utils.losses.data_losses.ICLoss object at 0x7f3fcae84880> + 0.1*<AP_neuralop_utils.losses.data_losses.BCNeumann object at 0x7f3eb9037a60>

 * Test: {'l2': <AP_neuralop_utils.losses.data_losses.LpLoss object at 0x7f3fcae84520>, 'mse': <neuralop.losses.data_losses.MSELoss object at 0x7f3fcae84550>, 'rmse': <AP_neuralop_utils.losses.data_losses.RMSELoss object at 0x7f3fcae844f0>, 'ap_phys': <AP_neuralop_utils.losses.equation_losses.APLoss object at 0x7f3eb8e01fa0>, 'boundary': <AP_neuralop_utils.losses.data_losses.BoundaryLoss object at 0x7f3fcae848e0>, 'ic': <AP_neuralop_utils.losses.data_losses.ICLoss object at 0x7f3fcae84880>, 'bcn': <AP_neuralop_utils.losses.data_losses.BCNeumann object at 0x7f3eb9037a60>, 'phys_loss': <AP_neuralop_utils.losses.meta_losses.WeightedSumLoss object at 0x7f3eb8e01dc0>}

 * Saving best model according to: mse
Saving best model according to (101, 1.0)_mse
Trainer resuming from epoch 99
Training on 152 samples
Testing on [30] samples         on resolutions [(101, 1.0)].
[100] time=15.34, avg_loss=0.9489, train_err=13.1125
Eval: (101, 1.0)_l2=3.1151, (101, 1.0)_mse=0.0349, (101, 1.0)_rmse=0.0372, (101, 1.0)_ap_phys=3.2285, (101, 1.0)_boundary=0.0178, (101, 1.0)_ic=0.0076, (101, 1.0)_bcn=0.0302, (101, 1.0)_phys_loss=0.0361
[Rank 0]: saved training state to Results_chaotic_PINO_1.0_500_mse_5_frames04_11_2025-10_55
[200] time=17.24, avg_loss=0.5910, train_err=8.1660
Eval: (101, 1.0)_l2=3.1118, (101, 1.0)_mse=0.0355, (101, 1.0)_rmse=0.0374, (101, 1.0)_ap_phys=2.7713, (101, 1.0)_boundary=0.0186, (101, 1.0)_ic=0.0070, (101, 1.0)_bcn=0.0333, (101, 1.0)_phys_loss=0.0317
[300] time=16.80, avg_loss=0.3868, train_err=5.3447
Eval: (101, 1.0)_l2=3.1786, (101, 1.0)_mse=0.0373, (101, 1.0)_rmse=0.0383, (101, 1.0)_ap_phys=2.8988, (101, 1.0)_boundary=0.0206, (101, 1.0)_ic=0.0070, (101, 1.0)_bcn=0.0361, (101, 1.0)_phys_loss=0.0333
[400] time=15.23, avg_loss=0.2844, train_err=3.9293
Eval: (101, 1.0)_l2=3.2551, (101, 1.0)_mse=0.0390, (101, 1.0)_rmse=0.0392, (101, 1.0)_ap_phys=2.7811, (101, 1.0)_boundary=0.0228, (101, 1.0)_ic=0.0073, (101, 1.0)_bcn=0.0384, (101, 1.0)_phys_loss=0.0324
[500] time=14.59, avg_loss=0.2102, train_err=2.9051
Eval: (101, 1.0)_l2=3.2871, (101, 1.0)_mse=0.0405, (101, 1.0)_rmse=0.0399, (101, 1.0)_ap_phys=2.8427, (101, 1.0)_boundary=0.0229, (101, 1.0)_ic=0.0068, (101, 1.0)_bcn=0.0388, (101, 1.0)_phys_loss=0.0330
