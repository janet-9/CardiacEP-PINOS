
### --------- ###

Loading datasets from /storage/ceph/usr/k23086865/Projects/PINNS/2D_AP_PINO/datasets/openCARP_Data/planar/0.8_trn-tst_200_frames_5_inputsteps_5_outputsteps_SEQ
datasets/openCARP_Data/planar/0.8_trn-tst_200_frames_5_inputsteps_5_outputsteps_SEQ/dataset_info_101_1.0.txt
dx: 0.09900990099009901
dy: 0.09900990099009901
delta_t: 5 ms
V_rest = 0.0, V_amp = 0.99
Time boundary: 5 frames
n_train: 152
training_resolution: 101

### --------- ###


### --------- ###

 Number of testing samples: [30]
 Testing resolutions: [101]
 Testing Conductivities: [1.0]
 Testing batch sizes: [5]

### --------- ###

Loading Training Dataset for resolution 101 with 152 samples with 1.0 conductivity multiplier
Loading Testing Dataset for resolution 101 with 30 samples with 1.0 conductivity multiplier
Input Tensor: torch.Size([30, 2, 5, 101, 101])
Output Tensor: torch.Size([30, 2, 5, 101, 101])

### --------- ###

Mesh size: 10 cm x 10 cm
Sample Time Boundary: 5 frames with spacing 5 ms =  20.0 ms 
Embedding Grid Boundaries = [[0, 20.0], [0, 10], [0, 10]]
Sample Data shape: torch.Size([2, 5, 101, 101]): channels=2, time=5, H=101, W=101


### --------- ###


Model has 9450530 parameters.
Calculating Residual Loss via Finite Difference

### INITIAL TRAINING ROUND ###


### MODEL ###
 FNO(
  (positional_embedding): GridEmbeddingND()
  (fno_blocks): FNOBlocks(
    (convs): ModuleList(
      (0-3): 4 x SpectralConv(
        (weight): DenseTensor(shape=torch.Size([32, 32, 8, 16, 9]), rank=None)
      )
    )
    (fno_skips): ModuleList(
      (0-3): 4 x Flattened1dConv(
        (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)
      )
    )
    (channel_mlp): ModuleList(
      (0-3): 4 x ChannelMLP(
        (fcs): ModuleList(
          (0): Conv1d(32, 16, kernel_size=(1,), stride=(1,))
          (1): Conv1d(16, 32, kernel_size=(1,), stride=(1,))
        )
      )
    )
    (channel_mlp_skips): ModuleList(
      (0-3): 4 x SoftGating()
    )
  )
  (lifting): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(5, 64, kernel_size=(1,), stride=(1,))
      (1): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
    )
  )
  (projection): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
      (1): Conv1d(64, 2, kernel_size=(1,), stride=(1,))
    )
  )
)

### OPTIMIZER ###
 AdamW (
Parameter Group 0
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-06
    initial_lr: 0.0005
    lr: 0.0005
    weight_decay: 1e-05
)

### SCHEDULER ###
 <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f73815bad90>

### LOSSES ###

 * Train: <AP_neuralop_utils.losses.data_losses.LpLoss object at 0x7f738136c0d0>

 * Test: {'l2': <AP_neuralop_utils.losses.data_losses.LpLoss object at 0x7f738136c0d0>, 'mse': <neuralop.losses.data_losses.MSELoss object at 0x7f738136c100>, 'rmse': <AP_neuralop_utils.losses.data_losses.RMSELoss object at 0x7f738136c0a0>, 'ap_phys': <AP_neuralop_utils.losses.equation_losses.APLoss object at 0x7f724437fd90>, 'boundary': <AP_neuralop_utils.losses.data_losses.BoundaryLoss object at 0x7f738136c490>, 'ic': <AP_neuralop_utils.losses.data_losses.ICLoss object at 0x7f738136c430>, 'bcn': <AP_neuralop_utils.losses.data_losses.BCNeumann object at 0x7f724437f0a0>}

 * Initial Training Round for 100 epochs
Training on 152 samples
Testing on [30] samples         on resolutions [(101, 1.0)].
Raw outputs of shape torch.Size([15, 2, 5, 101, 101])
[0] time=9.73, avg_loss=134.6661, train_err=1860.8412
Eval: (101, 1.0)_l2=7930377216.0000, (101, 1.0)_mse=0.0428, (101, 1.0)_rmse=0.0414, (101, 1.0)_ap_phys=0.3168, (101, 1.0)_boundary=0.0174, (101, 1.0)_ic=0.0066, (101, 1.0)_bcn=0.0002
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[10] time=9.26, avg_loss=29.5764, train_err=408.6924
Eval: (101, 1.0)_l2=1323649536.0000, (101, 1.0)_mse=0.0053, (101, 1.0)_rmse=0.0146, (101, 1.0)_ap_phys=0.0196, (101, 1.0)_boundary=0.0018, (101, 1.0)_ic=0.0002, (101, 1.0)_bcn=0.0000
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[20] time=12.27, avg_loss=21.2650, train_err=293.8430
Eval: (101, 1.0)_l2=813042304.0000, (101, 1.0)_mse=0.0045, (101, 1.0)_rmse=0.0134, (101, 1.0)_ap_phys=0.0066, (101, 1.0)_boundary=0.0017, (101, 1.0)_ic=0.0001, (101, 1.0)_bcn=0.0000
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[30] time=8.94, avg_loss=19.3506, train_err=267.3905
Eval: (101, 1.0)_l2=681110912.0000, (101, 1.0)_mse=0.0047, (101, 1.0)_rmse=0.0137, (101, 1.0)_ap_phys=0.0024, (101, 1.0)_boundary=0.0018, (101, 1.0)_ic=0.0000, (101, 1.0)_bcn=0.0001
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[40] time=10.44, avg_loss=17.7716, train_err=245.5717
Eval: (101, 1.0)_l2=562458944.0000, (101, 1.0)_mse=0.0048, (101, 1.0)_rmse=0.0138, (101, 1.0)_ap_phys=0.0014, (101, 1.0)_boundary=0.0019, (101, 1.0)_ic=0.0000, (101, 1.0)_bcn=0.0000
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[50] time=9.10, avg_loss=16.7015, train_err=230.7843
Eval: (101, 1.0)_l2=515492160.0000, (101, 1.0)_mse=0.0047, (101, 1.0)_rmse=0.0137, (101, 1.0)_ap_phys=0.0007, (101, 1.0)_boundary=0.0020, (101, 1.0)_ic=0.0000, (101, 1.0)_bcn=0.0000
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[60] time=11.66, avg_loss=14.8581, train_err=205.3118
Eval: (101, 1.0)_l2=372869152.0000, (101, 1.0)_mse=0.0046, (101, 1.0)_rmse=0.0136, (101, 1.0)_ap_phys=0.0006, (101, 1.0)_boundary=0.0021, (101, 1.0)_ic=0.0000, (101, 1.0)_bcn=0.0000
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[70] time=9.12, avg_loss=13.9761, train_err=193.1245
Eval: (101, 1.0)_l2=308567360.0000, (101, 1.0)_mse=0.0046, (101, 1.0)_rmse=0.0136, (101, 1.0)_ap_phys=0.0003, (101, 1.0)_boundary=0.0021, (101, 1.0)_ic=0.0000, (101, 1.0)_bcn=0.0000
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[80] time=13.08, avg_loss=13.6417, train_err=188.5032
Eval: (101, 1.0)_l2=278451072.0000, (101, 1.0)_mse=0.0046, (101, 1.0)_rmse=0.0136, (101, 1.0)_ap_phys=0.0005, (101, 1.0)_boundary=0.0022, (101, 1.0)_ic=0.0000, (101, 1.0)_bcn=0.0000
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[90] time=12.09, avg_loss=13.3857, train_err=184.9657
Eval: (101, 1.0)_l2=276103520.0000, (101, 1.0)_mse=0.0046, (101, 1.0)_rmse=0.0135, (101, 1.0)_ap_phys=0.0001, (101, 1.0)_boundary=0.0023, (101, 1.0)_ic=0.0000, (101, 1.0)_bcn=0.0000
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27

### MAIN TRAINING ROUND ###


### MODEL ###
 FNO(
  (positional_embedding): GridEmbeddingND()
  (fno_blocks): FNOBlocks(
    (convs): ModuleList(
      (0-3): 4 x SpectralConv(
        (weight): DenseTensor(shape=torch.Size([32, 32, 8, 16, 9]), rank=None)
      )
    )
    (fno_skips): ModuleList(
      (0-3): 4 x Flattened1dConv(
        (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)
      )
    )
    (channel_mlp): ModuleList(
      (0-3): 4 x ChannelMLP(
        (fcs): ModuleList(
          (0): Conv1d(32, 16, kernel_size=(1,), stride=(1,))
          (1): Conv1d(16, 32, kernel_size=(1,), stride=(1,))
        )
      )
    )
    (channel_mlp_skips): ModuleList(
      (0-3): 4 x SoftGating()
    )
  )
  (lifting): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(5, 64, kernel_size=(1,), stride=(1,))
      (1): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
    )
  )
  (projection): ChannelMLP(
    (fcs): ModuleList(
      (0): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
      (1): Conv1d(64, 2, kernel_size=(1,), stride=(1,))
    )
  )
)

### OPTIMIZER ###
 AdamW (
Parameter Group 0
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-06
    initial_lr: 0.0005
    lr: 0.0004877641290737878
    weight_decay: 1e-05
)

### SCHEDULER ###
 <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f73815bad90>

### AGGREGATOR ###
 SoftAdapt()

### LOSSES ###

 * Train: <AP_neuralop_utils.losses.data_losses.LpLoss object at 0x7f738136c0d0>

 * Test: {'l2': <AP_neuralop_utils.losses.data_losses.LpLoss object at 0x7f738136c0d0>, 'mse': <neuralop.losses.data_losses.MSELoss object at 0x7f738136c100>, 'rmse': <AP_neuralop_utils.losses.data_losses.RMSELoss object at 0x7f738136c0a0>, 'ap_phys': <AP_neuralop_utils.losses.equation_losses.APLoss object at 0x7f724437fd90>, 'boundary': <AP_neuralop_utils.losses.data_losses.BoundaryLoss object at 0x7f738136c490>, 'ic': <AP_neuralop_utils.losses.data_losses.ICLoss object at 0x7f738136c430>, 'bcn': <AP_neuralop_utils.losses.data_losses.BCNeumann object at 0x7f724437f0a0>}

 * Saving best model according to: mse
Saving best model according to (101, 1.0)_mse
Trainer resuming from epoch 99
Training on 152 samples
Testing on [30] samples         on resolutions [(101, 1.0)].
[100] time=12.07, avg_loss=11.1871, train_err=154.5848
Eval: (101, 1.0)_l2=144080384.0000, (101, 1.0)_mse=0.0042, (101, 1.0)_rmse=0.0130, (101, 1.0)_ap_phys=0.0005, (101, 1.0)_boundary=0.0023, (101, 1.0)_ic=0.0000, (101, 1.0)_bcn=0.0000
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[200] time=12.79, avg_loss=6.2029, train_err=85.7134
Eval: (101, 1.0)_l2=45408548.0000, (101, 1.0)_mse=0.0010, (101, 1.0)_rmse=0.0064, (101, 1.0)_ap_phys=0.0001, (101, 1.0)_boundary=0.0009, (101, 1.0)_ic=0.0000, (101, 1.0)_bcn=0.0000
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[300] time=12.38, avg_loss=3.1389, train_err=43.3742
Eval: (101, 1.0)_l2=103383232.0000, (101, 1.0)_mse=0.0009, (101, 1.0)_rmse=0.0059, (101, 1.0)_ap_phys=0.0001, (101, 1.0)_boundary=0.0008, (101, 1.0)_ic=0.0000, (101, 1.0)_bcn=0.0000
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[400] time=12.13, avg_loss=1.8237, train_err=25.1997
Eval: (101, 1.0)_l2=53689832.0000, (101, 1.0)_mse=0.0008, (101, 1.0)_rmse=0.0056, (101, 1.0)_ap_phys=0.0001, (101, 1.0)_boundary=0.0006, (101, 1.0)_ic=0.0000, (101, 1.0)_bcn=0.0000
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[500] time=6.83, avg_loss=1.7196, train_err=23.7617
Eval: (101, 1.0)_l2=61294008.0000, (101, 1.0)_mse=0.0007, (101, 1.0)_rmse=0.0052, (101, 1.0)_ap_phys=0.0001, (101, 1.0)_boundary=0.0007, (101, 1.0)_ic=0.0000, (101, 1.0)_bcn=0.0000
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[600] time=6.97, avg_loss=1.1183, train_err=15.4523
Eval: (101, 1.0)_l2=38017548.0000, (101, 1.0)_mse=0.0006, (101, 1.0)_rmse=0.0049, (101, 1.0)_ap_phys=0.0001, (101, 1.0)_boundary=0.0006, (101, 1.0)_ic=0.0000, (101, 1.0)_bcn=0.0000
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[700] time=6.96, avg_loss=0.7923, train_err=10.9476
Eval: (101, 1.0)_l2=31978268.0000, (101, 1.0)_mse=0.0006, (101, 1.0)_rmse=0.0048, (101, 1.0)_ap_phys=0.0001, (101, 1.0)_boundary=0.0005, (101, 1.0)_ic=0.0000, (101, 1.0)_bcn=0.0000
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[800] time=7.03, avg_loss=0.5672, train_err=7.8371
Eval: (101, 1.0)_l2=27072840.0000, (101, 1.0)_mse=0.0005, (101, 1.0)_rmse=0.0046, (101, 1.0)_ap_phys=0.0001, (101, 1.0)_boundary=0.0005, (101, 1.0)_ic=0.0000, (101, 1.0)_bcn=0.0000
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[900] time=7.04, avg_loss=0.4041, train_err=5.5843
Eval: (101, 1.0)_l2=26650968.0000, (101, 1.0)_mse=0.0005, (101, 1.0)_rmse=0.0045, (101, 1.0)_ap_phys=0.0001, (101, 1.0)_boundary=0.0005, (101, 1.0)_ic=0.0000, (101, 1.0)_bcn=0.0000
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[1000] time=6.69, avg_loss=0.3856, train_err=5.3277
Eval: (101, 1.0)_l2=26683428.0000, (101, 1.0)_mse=0.0005, (101, 1.0)_rmse=0.0045, (101, 1.0)_ap_phys=0.0000, (101, 1.0)_boundary=0.0005, (101, 1.0)_ic=0.0000, (101, 1.0)_bcn=0.0000
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[1100] time=6.98, avg_loss=0.4393, train_err=6.0699
Eval: (101, 1.0)_l2=28394268.0000, (101, 1.0)_mse=0.0005, (101, 1.0)_rmse=0.0045, (101, 1.0)_ap_phys=0.0000, (101, 1.0)_boundary=0.0005, (101, 1.0)_ic=0.0000, (101, 1.0)_bcn=0.0000
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[1200] time=7.00, avg_loss=0.6006, train_err=8.2986
Eval: (101, 1.0)_l2=33761204.0000, (101, 1.0)_mse=0.0005, (101, 1.0)_rmse=0.0044, (101, 1.0)_ap_phys=0.0000, (101, 1.0)_boundary=0.0005, (101, 1.0)_ic=0.0000, (101, 1.0)_bcn=0.0000
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[1300] time=7.11, avg_loss=0.9833, train_err=13.5880
Eval: (101, 1.0)_l2=39893692.0000, (101, 1.0)_mse=0.0005, (101, 1.0)_rmse=0.0043, (101, 1.0)_ap_phys=0.0001, (101, 1.0)_boundary=0.0005, (101, 1.0)_ic=0.0000, (101, 1.0)_bcn=0.0000
[Rank 0]: saved training state to Results_planar_PINO_2.0_1500_mse_5_frames02_11_2025-20_27
[1400] time=6.97, avg_loss=1.2984, train_err=17.9418
Eval: (101, 1.0)_l2=64983344.0000, (101, 1.0)_mse=0.0005, (101, 1.0)_rmse=0.0044, (101, 1.0)_ap_phys=0.0001, (101, 1.0)_boundary=0.0005, (101, 1.0)_ic=0.0000, (101, 1.0)_bcn=0.0000
[1500] time=6.85, avg_loss=1.5313, train_err=21.1602
Eval: (101, 1.0)_l2=77885384.0000, (101, 1.0)_mse=0.0005, (101, 1.0)_rmse=0.0045, (101, 1.0)_ap_phys=0.0000, (101, 1.0)_boundary=0.0004, (101, 1.0)_ic=0.0000, (101, 1.0)_bcn=0.0000
